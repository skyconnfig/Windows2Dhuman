#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç³»ç»Ÿç¡¬ä»¶é…ç½®æ£€æµ‹å’Œä¼˜åŒ–å»ºè®®è„šæœ¬
é€‚ç”¨äº2Dæ•°å­—äººé¡¹ç›®çš„Windowséƒ¨ç½²

ä½¿ç”¨æ–¹æ³•:
    python system_check.py
"""

import os
import sys
import platform
import psutil
import subprocess
import json
from pathlib import Path

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

try:
    import cv2
    OPENCV_AVAILABLE = True
except ImportError:
    OPENCV_AVAILABLE = False

class SystemChecker:
    def __init__(self):
        self.results = {
            'system_info': {},
            'hardware_check': {},
            'software_check': {},
            'performance_test': {},
            'recommendations': []
        }
    
    def check_system_info(self):
        """æ£€æŸ¥ç³»ç»ŸåŸºæœ¬ä¿¡æ¯"""
        print("ğŸ” æ£€æŸ¥ç³»ç»Ÿä¿¡æ¯...")
        
        system_info = {
            'os': platform.system(),
            'os_version': platform.version(),
            'architecture': platform.architecture()[0],
            'processor': platform.processor(),
            'python_version': platform.python_version()
        }
        
        self.results['system_info'] = system_info
        
        print(f"   æ“ä½œç³»ç»Ÿ: {system_info['os']} {system_info['os_version']}")
        print(f"   æ¶æ„: {system_info['architecture']}")
        print(f"   Pythonç‰ˆæœ¬: {system_info['python_version']}")
        
        return system_info
    
    def check_hardware(self):
        """æ£€æŸ¥ç¡¬ä»¶é…ç½®"""
        print("\nğŸ”§ æ£€æŸ¥ç¡¬ä»¶é…ç½®...")
        
        # CPUä¿¡æ¯
        cpu_count = psutil.cpu_count(logical=False)
        cpu_count_logical = psutil.cpu_count(logical=True)
        cpu_freq = psutil.cpu_freq()
        
        # å†…å­˜ä¿¡æ¯
        memory = psutil.virtual_memory()
        memory_gb = round(memory.total / (1024**3), 2)
        
        # ç£ç›˜ä¿¡æ¯
        disk_usage = psutil.disk_usage('/')
        disk_free_gb = round(disk_usage.free / (1024**3), 2)
        
        hardware_info = {
            'cpu_cores_physical': cpu_count,
            'cpu_cores_logical': cpu_count_logical,
            'cpu_frequency_mhz': cpu_freq.current if cpu_freq else 0,
            'memory_total_gb': memory_gb,
            'memory_available_gb': round(memory.available / (1024**3), 2),
            'disk_free_gb': disk_free_gb
        }
        
        self.results['hardware_check'] = hardware_info
        
        print(f"   CPUæ ¸å¿ƒ: {cpu_count}ç‰©ç†æ ¸å¿ƒ, {cpu_count_logical}é€»è¾‘æ ¸å¿ƒ")
        print(f"   CPUé¢‘ç‡: {cpu_freq.current:.0f} MHz" if cpu_freq else "   CPUé¢‘ç‡: æœªçŸ¥")
        print(f"   å†…å­˜: {memory_gb:.1f}GB æ€»è®¡, {hardware_info['memory_available_gb']:.1f}GB å¯ç”¨")
        print(f"   ç£ç›˜ç©ºé—´: {disk_free_gb:.1f}GB å¯ç”¨")
        
        return hardware_info
    
    def check_gpu(self):
        """æ£€æŸ¥GPUé…ç½®"""
        print("\nğŸ® æ£€æŸ¥GPUé…ç½®...")
        
        gpu_info = {
            'cuda_available': False,
            'gpu_count': 0,
            'gpu_names': [],
            'gpu_memory': []
        }
        
        if TORCH_AVAILABLE:
            gpu_info['cuda_available'] = torch.cuda.is_available()
            if gpu_info['cuda_available']:
                gpu_info['gpu_count'] = torch.cuda.device_count()
                for i in range(gpu_info['gpu_count']):
                    gpu_name = torch.cuda.get_device_name(i)
                    gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)
                    gpu_info['gpu_names'].append(gpu_name)
                    gpu_info['gpu_memory'].append(round(gpu_memory, 2))
                    print(f"   GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)")
            else:
                print("   CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
        else:
            print("   PyTorchæœªå®‰è£…ï¼Œæ— æ³•æ£€æµ‹GPU")
        
        self.results['hardware_check']['gpu'] = gpu_info
        return gpu_info
    
    def check_software_dependencies(self):
        """æ£€æŸ¥è½¯ä»¶ä¾èµ–"""
        print("\nğŸ“¦ æ£€æŸ¥è½¯ä»¶ä¾èµ–...")
        
        dependencies = {
            'torch': TORCH_AVAILABLE,
            'opencv': OPENCV_AVAILABLE,
            'gradio': self._check_package('gradio'),
            'mediapipe': self._check_package('mediapipe'),
            'numpy': self._check_package('numpy'),
            'scipy': self._check_package('scipy'),
            'scikit-learn': self._check_package('sklearn'),
            'kaldi_native_fbank': self._check_package('kaldi_native_fbank')
        }
        
        self.results['software_check'] = dependencies
        
        for package, available in dependencies.items():
            status = "âœ…" if available else "âŒ"
            print(f"   {status} {package}")
        
        return dependencies
    
    def _check_package(self, package_name):
        """æ£€æŸ¥PythonåŒ…æ˜¯å¦å®‰è£…"""
        try:
            __import__(package_name)
            return True
        except ImportError:
            return False
    
    def performance_test(self):
        """ç®€å•çš„æ€§èƒ½æµ‹è¯•"""
        print("\nâš¡ è¿›è¡Œæ€§èƒ½æµ‹è¯•...")
        
        import time
        import numpy as np
        
        # CPUæµ‹è¯•
        print("   æµ‹è¯•CPUæ€§èƒ½...")
        start_time = time.time()
        
        # çŸ©é˜µè¿ç®—æµ‹è¯•
        for _ in range(100):
            a = np.random.rand(500, 500)
            b = np.random.rand(500, 500)
            c = np.dot(a, b)
        
        cpu_time = time.time() - start_time
        
        performance_info = {
            'cpu_matrix_test_time': round(cpu_time, 3)
        }
        
        # GPUæµ‹è¯•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if TORCH_AVAILABLE and torch.cuda.is_available():
            print("   æµ‹è¯•GPUæ€§èƒ½...")
            device = torch.device('cuda')
            start_time = time.time()
            
            for _ in range(100):
                a = torch.rand(500, 500, device=device)
                b = torch.rand(500, 500, device=device)
                c = torch.mm(a, b)
                torch.cuda.synchronize()
            
            gpu_time = time.time() - start_time
            performance_info['gpu_matrix_test_time'] = round(gpu_time, 3)
            
            print(f"   CPUçŸ©é˜µè¿ç®—: {cpu_time:.3f}ç§’")
            print(f"   GPUçŸ©é˜µè¿ç®—: {gpu_time:.3f}ç§’")
            print(f"   GPUåŠ é€Ÿæ¯”: {cpu_time/gpu_time:.1f}x")
        else:
            print(f"   CPUçŸ©é˜µè¿ç®—: {cpu_time:.3f}ç§’")
        
        self.results['performance_test'] = performance_info
        return performance_info
    
    def generate_recommendations(self):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        print("\nğŸ’¡ ç”Ÿæˆä¼˜åŒ–å»ºè®®...")
        
        recommendations = []
        
        # æ£€æŸ¥CPU
        cpu_cores = self.results['hardware_check']['cpu_cores_physical']
        if cpu_cores < 6:
            recommendations.append({
                'type': 'warning',
                'message': f'CPUæ ¸å¿ƒæ•°({cpu_cores})ä½äºæ¨èé…ç½®(6æ ¸å¿ƒ+)ï¼Œå¯èƒ½å½±å“æ€§èƒ½'
            })
        
        # æ£€æŸ¥å†…å­˜
        memory_gb = self.results['hardware_check']['memory_total_gb']
        if memory_gb < 8:
            recommendations.append({
                'type': 'error',
                'message': f'å†…å­˜å®¹é‡({memory_gb:.1f}GB)ä½äºæœ€ä½è¦æ±‚(8GB)ï¼Œå»ºè®®å‡çº§å†…å­˜'
            })
        elif memory_gb < 16:
            recommendations.append({
                'type': 'info',
                'message': f'å†…å­˜å®¹é‡({memory_gb:.1f}GB)æ»¡è¶³æœ€ä½è¦æ±‚ï¼Œå»ºè®®å‡çº§åˆ°16GBä»¥è·å¾—æ›´å¥½æ€§èƒ½'
            })
        
        # æ£€æŸ¥ç£ç›˜ç©ºé—´
        disk_free = self.results['hardware_check']['disk_free_gb']
        if disk_free < 5:
            recommendations.append({
                'type': 'error',
                'message': f'ç£ç›˜å¯ç”¨ç©ºé—´({disk_free:.1f}GB)ä¸è¶³ï¼Œå»ºè®®æ¸…ç†ç£ç›˜ç©ºé—´'
            })
        elif disk_free < 10:
            recommendations.append({
                'type': 'warning',
                'message': f'ç£ç›˜å¯ç”¨ç©ºé—´({disk_free:.1f}GB)è¾ƒå°‘ï¼Œå»ºè®®é¢„ç•™æ›´å¤šç©ºé—´'
            })
        
        # æ£€æŸ¥GPU
        if 'gpu' in self.results['hardware_check']:
            gpu_info = self.results['hardware_check']['gpu']
            if not gpu_info['cuda_available']:
                recommendations.append({
                    'type': 'info',
                    'message': 'æœªæ£€æµ‹åˆ°CUDAæ”¯æŒï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼è¿è¡Œï¼Œæ€§èƒ½å¯èƒ½è¾ƒæ…¢'
                })
            elif gpu_info['gpu_count'] > 0:
                for i, memory in enumerate(gpu_info['gpu_memory']):
                    if memory < 2:
                        recommendations.append({
                            'type': 'warning',
                            'message': f'GPU {i} æ˜¾å­˜({memory:.1f}GB)è¾ƒå°‘ï¼Œå¯èƒ½å½±å“å¤§æ¨¡å‹è¿è¡Œ'
                        })
        
        # æ£€æŸ¥è½¯ä»¶ä¾èµ–
        missing_packages = []
        for package, available in self.results['software_check'].items():
            if not available:
                missing_packages.append(package)
        
        if missing_packages:
            recommendations.append({
                'type': 'error',
                'message': f'ç¼ºå°‘å¿…è¦ä¾èµ–åŒ…: {", ".join(missing_packages)}ï¼Œè¯·è¿è¡Œ pip install -r requirements.txt'
            })
        
        # æ€§èƒ½å»ºè®®
        if 'cpu_matrix_test_time' in self.results['performance_test']:
            cpu_time = self.results['performance_test']['cpu_matrix_test_time']
            if cpu_time > 5.0:
                recommendations.append({
                    'type': 'warning',
                    'message': f'CPUæ€§èƒ½æµ‹è¯•è€—æ—¶({cpu_time:.1f}ç§’)è¾ƒé•¿ï¼Œå»ºè®®å‡çº§CPUæˆ–å¯ç”¨GPUåŠ é€Ÿ'
                })
        
        self.results['recommendations'] = recommendations
        
        # æ‰“å°å»ºè®®
        for rec in recommendations:
            icon = {'error': 'âŒ', 'warning': 'âš ï¸', 'info': 'â„¹ï¸'}[rec['type']]
            print(f"   {icon} {rec['message']}")
        
        if not recommendations:
            print("   âœ… ç³»ç»Ÿé…ç½®è‰¯å¥½ï¼Œæ— éœ€ç‰¹åˆ«ä¼˜åŒ–")
        
        return recommendations
    
    def save_report(self, filename='system_check_report.json'):
        """ä¿å­˜æ£€æµ‹æŠ¥å‘Š"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ“„ æ£€æµ‹æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
    
    def run_full_check(self):
        """è¿è¡Œå®Œæ•´çš„ç³»ç»Ÿæ£€æµ‹"""
        print("ğŸš€ å¼€å§‹ç³»ç»Ÿç¡¬ä»¶é…ç½®æ£€æµ‹...\n")
        
        self.check_system_info()
        self.check_hardware()
        self.check_gpu()
        self.check_software_dependencies()
        self.performance_test()
        self.generate_recommendations()
        
        print("\nâœ… ç³»ç»Ÿæ£€æµ‹å®Œæˆï¼")
        
        # ä¿å­˜æŠ¥å‘Š
        self.save_report()
        
        return self.results

def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("    2Dæ•°å­—äººé¡¹ç›® - Windowsç³»ç»Ÿé…ç½®æ£€æµ‹å·¥å…·")
    print("="*60)
    
    checker = SystemChecker()
    results = checker.run_full_check()
    
    print("\n" + "="*60)
    print("æ£€æµ‹å®Œæˆï¼è¯·æŸ¥çœ‹ä¸Šè¿°å»ºè®®è¿›è¡Œç³»ç»Ÿä¼˜åŒ–ã€‚")
    print("å¦‚éœ€æŠ€æœ¯æ”¯æŒï¼Œè¯·å°†ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶ä¸€å¹¶æä¾›ã€‚")
    print("="*60)

if __name__ == '__main__':
    main()